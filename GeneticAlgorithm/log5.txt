01/24/2018 10:59:27 PM - INFO - ***Evolving 10 generations with population 50***
01/24/2018 10:59:27 PM - INFO - ***Doing generation 1 of 10***
01/24/2018 10:59:49 PM - INFO - {'nb_neurons': 56, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.9, 'learning_rate': 0.02}
[0.69280174645510584, 0.48106060606060608]



01/24/2018 11:00:04 PM - INFO - {'nb_neurons': 8, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adam', 'dropout': 0.25, 'learning_rate': 0.01}
[1.4941786150589134, 0.75757575757575757]



01/24/2018 11:00:34 PM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.65, 'learning_rate': 0.02}
[0.60856896638870239, 0.76893939393939392]



01/24/2018 11:14:11 PM - INFO - {'nb_neurons': 122, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'adadelta', 'dropout': 0.55, 'learning_rate': 0.01}
[0.53555984749938501, 0.73863636363636365]



01/24/2018 11:15:09 PM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'sgd', 'dropout': 0.25, 'learning_rate': 0.01}
[0.54992207794478443, 0.73863636363636365]



01/24/2018 11:17:16 PM - INFO - {'nb_neurons': 32, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'sgd', 'dropout': 0.6, 'learning_rate': 0.005}
[0.69282666300282336, 0.48863636363636365]



01/24/2018 11:17:40 PM - INFO - {'nb_neurons': 88, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.45, 'learning_rate': 0.01}
[0.86566086926243524, 0.76136363636363635]



01/24/2018 11:18:00 PM - INFO - {'nb_neurons': 40, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.45, 'learning_rate': 0.05}
[0.99212156281326758, 0.76893939393939392]



01/24/2018 11:18:25 PM - INFO - {'nb_neurons': 72, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.02}
[0.58249001250122534, 0.78030303030303028]



01/24/2018 11:19:59 PM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.59059713645414869, 0.81060606060606055]



01/24/2018 11:25:26 PM - INFO - {'nb_neurons': 108, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adadelta', 'dropout': 0.3, 'learning_rate': 0.02}
[0.52839109030636877, 0.73106060606060608]



01/24/2018 11:33:29 PM - INFO - {'nb_neurons': 32, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adadelta', 'dropout': 0.45, 'learning_rate': 0.01}
[0.55418297016259399, 0.73863636363636365]



01/24/2018 11:33:58 PM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.02}
[0.72432187018972449, 0.79545454545454541]



01/24/2018 11:45:16 PM - INFO - {'nb_neurons': 72, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adadelta', 'dropout': 0.45, 'learning_rate': 0.02}
[0.6905903635603009, 0.61742424242424243]



01/24/2018 11:52:57 PM - INFO - {'nb_neurons': 64, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adadelta', 'dropout': 0.4, 'learning_rate': 0.05}
[0.53747114629456494, 0.73863636363636365]



01/24/2018 11:55:55 PM - INFO - {'nb_neurons': 56, 'nb_layers': 2, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.9, 'learning_rate': 0.01}
[0.50601216247587488, 0.73484848484848486]



01/25/2018 12:01:28 AM - INFO - {'nb_neurons': 16, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.65, 'learning_rate': 0.005}
[0.55226976401878125, 0.73484848484848486]



01/25/2018 12:01:46 AM - INFO - {'nb_neurons': 40, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.8033126086899729, 0.76893939393939392]



01/25/2018 12:04:27 AM - INFO - {'nb_neurons': 88, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adadelta', 'dropout': 0.6, 'learning_rate': 0.05}
[0.52644136818972498, 0.75378787878787878]



01/25/2018 12:08:50 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'sgd', 'dropout': 0.4, 'learning_rate': 0.02}
[0.69303030498100049, 0.5]



01/25/2018 12:09:20 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.55, 'learning_rate': 0.01}
[0.59804111493356304, 0.77272727272727271]



01/25/2018 12:10:41 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.85, 'learning_rate': 0.01}
[0.54587078816962964, 0.75757575757575757]



01/25/2018 12:12:03 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'sgd', 'dropout': 0.45, 'learning_rate': 0.02}
[0.55190429272073693, 0.75757575757575757]



01/25/2018 12:12:36 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[1.0626295757564632, 0.78409090909090906]



01/25/2018 12:13:02 AM - INFO - {'nb_neurons': 16, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.9, 'learning_rate': 0.05}
[0.5919297861330437, 0.73484848484848486]



01/25/2018 12:13:55 AM - INFO - {'nb_neurons': 48, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.01}
[0.58668113116062048, 0.77272727272727271]



01/25/2018 12:14:15 AM - INFO - {'nb_neurons': 64, 'nb_layers': 2, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.02}
[1.8296797582597444, 0.73484848484848486]



01/25/2018 12:14:56 AM - INFO - {'nb_neurons': 256, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.77561249696847168, 0.79166666666666663]



01/25/2018 12:16:14 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.8, 'learning_rate': 0.01}
[0.68975471547155665, 0.76515151515151514]



01/25/2018 12:17:36 AM - INFO - {'nb_neurons': 102, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'sgd', 'dropout': 0.75, 'learning_rate': 0.02}
[0.52117874224980676, 0.74242424242424243]



01/25/2018 12:18:09 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.005}
[0.72250566157427698, 0.78787878787878785]



01/25/2018 12:19:00 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'sgd', 'dropout': 0.45, 'learning_rate': 0.02}
[0.54545026836973243, 0.74621212121212122]



01/25/2018 12:19:41 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.9, 'learning_rate': 0.01}
[0.54095743099848426, 0.76893939393939392]



01/25/2018 12:20:13 AM - INFO - {'nb_neurons': 32, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.65, 'learning_rate': 0.01}
[0.81870734781929944, 0.78409090909090906]



01/25/2018 12:22:02 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'sgd', 'dropout': 0.7, 'learning_rate': 0.05}
[0.5623415356332605, 0.73106060606060608]



01/25/2018 12:22:48 AM - INFO - {'nb_neurons': 8, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.75, 'learning_rate': 0.01}
[0.5189013571450205, 0.78030303030303028]



01/25/2018 12:23:21 AM - INFO - {'nb_neurons': 88, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adam', 'dropout': 0.5, 'learning_rate': 0.02}
[0.82334172274127149, 0.73106060606060608]



01/25/2018 12:23:45 AM - INFO - {'nb_neurons': 40, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adamax', 'dropout': 0.3, 'learning_rate': 0.02}
[0.68383683219100488, 0.74242424242424243]



01/25/2018 12:24:06 AM - INFO - {'nb_neurons': 40, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.3, 'learning_rate': 0.01}
[1.3191707495487097, 0.77651515151515149]



01/25/2018 12:25:20 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.75, 'learning_rate': 0.02}
[0.72216012938456098, 0.78030303030303028]



01/25/2018 12:25:42 AM - INFO - {'nb_neurons': 72, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adam', 'dropout': 0.4, 'learning_rate': 0.02}
[1.4562251965204875, 0.76515151515151514]



01/25/2018 12:26:08 AM - INFO - {'nb_neurons': 80, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.45, 'learning_rate': 0.005}
[0.75245035236532043, 0.76136363636363635]



01/25/2018 12:34:23 AM - INFO - {'nb_neurons': 32, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adadelta', 'dropout': 0.4, 'learning_rate': 0.02}
[0.51917362032514625, 0.74242424242424243]



01/25/2018 12:34:52 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.6, 'learning_rate': 0.01}
[0.68839373552437988, 0.78409090909090906]



01/25/2018 12:35:24 AM - INFO - {'nb_neurons': 80, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.65881124274297198, 0.77272727272727271]



01/25/2018 12:35:51 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.80979030398708396, 0.78787878787878785]



01/25/2018 12:43:17 AM - INFO - {'nb_neurons': 16, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adadelta', 'dropout': 0.6, 'learning_rate': 0.005}
[0.6902580008362279, 0.5757575757575758]



01/25/2018 12:44:01 AM - INFO - {'nb_neurons': 72, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.6, 'learning_rate': 0.05}
[0.52534733938448352, 0.73484848484848486]



01/25/2018 12:44:38 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.6, 'learning_rate': 0.005}
[0.68367601118304511, 0.77272727272727271]



01/25/2018 12:45:03 AM - INFO - {'nb_neurons': 72, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adamax', 'dropout': 0.8, 'learning_rate': 0.05}
[0.69314718246459961, 0.5]



01/25/2018 12:45:03 AM - INFO - Generation average: 73.30%
01/25/2018 12:45:03 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 12:45:03 AM - INFO - ***Doing generation 2 of 10***
01/25/2018 12:45:27 AM - INFO - {'nb_neurons': 32, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.55, 'learning_rate': 0.01}
[1.0047731011202841, 0.76136363636363635]



01/25/2018 12:46:05 AM - INFO - {'nb_neurons': 122, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.55, 'learning_rate': 0.01}
[1.3102526565392811, 0.73863636363636365]



01/25/2018 12:46:40 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.5970832813869823, 0.79166666666666663]



01/25/2018 12:47:14 AM - INFO - {'nb_neurons': 108, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.9, 'learning_rate': 0.01}
[0.69341290719581372, 0.5]



01/25/2018 12:47:33 AM - INFO - {'nb_neurons': 16, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.02}
[0.68341898556911584, 0.68939393939393945]



01/25/2018 12:48:08 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.02}
[0.6414090431097782, 0.66287878787878785]



01/25/2018 12:48:28 AM - INFO - {'nb_neurons': 40, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.45, 'learning_rate': 0.05}
[1.1103888461084077, 0.75757575757575757]



01/25/2018 12:49:01 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.02}
[0.61715925010767847, 0.78787878787878785]



01/25/2018 12:49:34 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.9, 'learning_rate': 0.01}
[0.72634217955849389, 0.76515151515151514]



01/25/2018 12:50:07 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.9, 'learning_rate': 0.01}
[0.69319524909510755, 0.5]



01/25/2018 12:50:38 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.01}
[0.72715186169653223, 0.78409090909090906]



01/25/2018 12:51:14 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.6, 'learning_rate': 0.01}
[0.82829008409471228, 0.78409090909090906]



01/25/2018 12:52:00 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.55892498881527874, 0.79166666666666663]



01/25/2018 12:53:42 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.54338705494548334, 0.78409090909090906]



01/25/2018 12:54:18 AM - INFO - {'nb_neurons': 48, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.01}
[0.55787229267033667, 0.78409090909090906]



01/25/2018 12:54:53 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[1.4084546082850657, 0.75]



01/25/2018 12:55:13 AM - INFO - {'nb_neurons': 40, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.61499112663847022, 0.78030303030303028]



01/25/2018 12:55:58 AM - INFO - {'nb_neurons': 256, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.77683376001589222, 0.76893939393939392]



01/25/2018 12:56:22 AM - INFO - {'nb_neurons': 8, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adam', 'dropout': 0.7, 'learning_rate': 0.01}
[0.54278779481396533, 0.75757575757575757]



01/25/2018 12:56:53 AM - INFO - {'nb_neurons': 72, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adamax', 'dropout': 0.75, 'learning_rate': 0.02}
[0.55514481121843506, 0.78409090909090906]



01/25/2018 12:58:00 AM - INFO - {'nb_neurons': 256, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.71326667251008935, 0.5]



01/25/2018 12:58:35 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.6, 'learning_rate': 0.05}
[0.57676113645235694, 0.76893939393939392]



01/25/2018 12:59:40 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.7, 'learning_rate': 0.01}
[0.55108450217680494, 0.77272727272727271]



01/25/2018 01:00:20 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.57137710397893737, 0.76893939393939392]



01/25/2018 01:01:06 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adamax', 'dropout': 0.9, 'learning_rate': 0.01}
[0.51549743702917383, 0.76893939393939392]



01/25/2018 01:01:39 AM - INFO - {'nb_neurons': 48, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.57543271599393897, 0.78030303030303028]



01/25/2018 01:02:15 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.1510698343768264, 0.79545454545454541]



01/25/2018 01:03:43 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.02}
[0.65494428326686227, 0.76893939393939392]



01/25/2018 01:03:43 AM - INFO - Generation average: 75.50%
01/25/2018 01:03:43 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 01:03:43 AM - INFO - ***Doing generation 3 of 10***
01/25/2018 01:04:28 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.01}
[0.57848138475056854, 0.76515151515151514]



01/25/2018 01:05:05 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.85, 'learning_rate': 0.05}
[0.69326485106439306, 0.5]



01/25/2018 01:05:27 AM - INFO - {'nb_neurons': 48, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[1.1880375137834838, 0.77272727272727271]



01/25/2018 01:06:07 AM - INFO - {'nb_neurons': 122, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.55, 'learning_rate': 0.01}
[0.67106265552116162, 0.78409090909090906]



01/25/2018 01:07:52 AM - INFO - {'nb_neurons': 8, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.01}
[0.52908981568885571, 0.73863636363636365]



01/25/2018 01:08:14 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0068093723419942, 0.79545454545454541]



01/25/2018 01:09:16 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.005}
[0.71344484524293383, 0.77651515151515149]



01/25/2018 01:09:57 AM - INFO - {'nb_neurons': 32, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.005}
[0.85604825796503015, 0.75378787878787878]



01/25/2018 01:10:59 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.9, 'learning_rate': 0.01}
[0.69322121865821607, 0.5]



01/25/2018 01:11:27 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.65, 'learning_rate': 0.01}
[0.69159064419341809, 0.78409090909090906]



01/25/2018 01:11:54 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.77412415273261792, 0.78409090909090906]



01/25/2018 01:12:28 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.9, 'learning_rate': 0.01}
[5.0359952666542744, 0.62121212121212122]



01/25/2018 01:13:00 AM - INFO - {'nb_neurons': 122, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.6, 'learning_rate': 0.01}
[0.71465110282103217, 0.76893939393939392]



01/25/2018 01:13:30 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.55, 'learning_rate': 0.01}
[0.71750223094766785, 0.78787878787878785]



01/25/2018 01:13:55 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.72498391342885571, 0.76515151515151514]



01/25/2018 01:14:22 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.72106591047662683, 0.79166666666666663]



01/25/2018 01:14:46 AM - INFO - {'nb_neurons': 32, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.65, 'learning_rate': 0.01}
[1.1466083111185017, 0.77651515151515149]



01/25/2018 01:15:24 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.65, 'learning_rate': 0.01}
[0.74087829662091809, 0.78030303030303028]



01/25/2018 01:16:03 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.02}
[6.2645386493567266, 0.60984848484848486]



01/25/2018 01:16:39 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.89496423371813516, 0.79545454545454541]



01/25/2018 01:17:43 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.85, 'learning_rate': 0.01}
[0.5727101505705805, 0.75]



01/25/2018 01:18:19 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.85, 'learning_rate': 0.01}
[2.7073874618067886, 0.50378787878787878]



01/25/2018 01:18:50 AM - INFO - {'nb_neurons': 108, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.02}
[4.4035274476716015, 0.72348484848484851]



01/25/2018 01:18:50 AM - INFO - Generation average: 74.92%
01/25/2018 01:18:50 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 01:18:50 AM - INFO - ***Doing generation 4 of 10***
01/25/2018 01:21:13 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.56418651342391968, 0.77651515151515149]



01/25/2018 01:22:57 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.5460372278184602, 0.76893939393939392]



01/25/2018 01:23:31 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.005}
[0.69333420739029394, 0.77651515151515149]



01/25/2018 01:24:21 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.01}
[0.64824720675295044, 0.76136363636363635]



01/25/2018 01:25:21 AM - INFO - {'nb_neurons': 80, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.01}
[0.5632940006978584, 0.75378787878787878]



01/25/2018 01:27:37 AM - INFO - {'nb_neurons': 80, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.05}
[0.61270171042644617, 0.74621212121212122]



01/25/2018 01:28:38 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.005}
[0.58335160847866174, 0.73863636363636365]



01/25/2018 01:29:51 AM - INFO - {'nb_neurons': 80, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.01}
[0.56732089049888379, 0.74621212121212122]



01/25/2018 01:30:31 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.02}
[0.65403576150084985, 0.70454545454545459]



01/25/2018 01:31:39 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.02}
[0.55673267082734545, 0.75]



01/25/2018 01:32:16 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.6, 'learning_rate': 0.01}
[0.77518963531562779, 0.79166666666666663]



01/25/2018 01:32:55 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.0531026544896038, 0.79166666666666663]



01/25/2018 01:33:17 AM - INFO - {'nb_neurons': 32, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.65, 'learning_rate': 0.01}
[0.64165703320141998, 0.78787878787878785]



01/25/2018 01:33:49 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.01}
[0.72069838868849201, 0.78787878787878785]



01/25/2018 01:34:24 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.75, 'learning_rate': 0.005}
[0.94184604196837451, 0.76893939393939392]



01/25/2018 01:35:10 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.005}
[0.53911626790509082, 0.76136363636363635]



01/25/2018 01:36:09 AM - INFO - {'nb_neurons': 32, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.57560749487443408, 0.74621212121212122]



01/25/2018 01:36:48 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.65, 'learning_rate': 0.05}
[7.9711923599243164, 0.5]



01/25/2018 01:37:21 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[1.2175747142596678, 0.77272727272727271]



01/25/2018 01:38:16 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.7, 'learning_rate': 0.05}
[0.5433095747774298, 0.73106060606060608]



01/25/2018 01:39:08 AM - INFO - {'nb_neurons': 32, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.65, 'learning_rate': 0.05}
[0.79685269431634387, 0.72348484848484851]



01/25/2018 01:39:56 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.01}
[0.61020138363043464, 0.76136363636363635]



01/25/2018 01:40:28 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0651278324199445, 0.78030303030303028]



01/25/2018 01:41:00 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[1.5618196129798889, 0.77272727272727271]



01/25/2018 01:41:34 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.01}
[0.85159398208964954, 0.76136363636363635]



01/25/2018 01:42:10 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.75, 'learning_rate': 0.01}
[0.82909932145566656, 0.77272727272727271]



01/25/2018 01:42:57 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.64899985401919391, 0.78030303030303028]



01/25/2018 01:43:49 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.68486161304242688, 0.78787878787878785]



01/25/2018 01:44:29 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.02}
[0.9972038016174779, 0.77651515151515149]



01/25/2018 01:44:29 AM - INFO - Generation average: 76.90%
01/25/2018 01:44:29 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 01:44:29 AM - INFO - ***Doing generation 5 of 10***
01/25/2018 01:45:46 AM - INFO - {'nb_neurons': 256, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.2, 'learning_rate': 0.05}
[0.68549437414516101, 0.76893939393939392]



01/25/2018 01:46:23 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.56225400982481055, 0.78030303030303028]



01/25/2018 01:46:53 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.6, 'learning_rate': 0.01}
[0.66521143055323395, 0.78030303030303028]



01/25/2018 01:47:22 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.6, 'learning_rate': 0.01}
[0.6575750162204107, 0.78030303030303028]



01/25/2018 01:47:52 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.6, 'learning_rate': 0.01}
[0.57339254653815064, 0.76893939393939392]



01/25/2018 01:48:43 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.68331571871584107, 0.78787878787878785]



01/25/2018 01:49:22 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.01}
[0.91536769180586841, 0.76515151515151514]



01/25/2018 01:49:54 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.01}
[0.92199818812536471, 0.79545454545454541]



01/25/2018 01:50:27 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.02}
[0.90477092338330822, 0.78787878787878785]



01/25/2018 01:50:55 AM - INFO - {'nb_neurons': 72, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.02}
[0.83793516863476147, 0.77272727272727271]



01/25/2018 01:51:33 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.1218188603719075, 0.75]



01/25/2018 01:52:06 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0725315908590953, 0.77651515151515149]



01/25/2018 01:52:32 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.66097290317217505, 0.77272727272727271]



01/25/2018 01:53:07 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0574020307623979, 0.78030303030303028]



01/25/2018 01:53:54 AM - INFO - {'nb_neurons': 256, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.78314503575816297, 0.74621212121212122]



01/25/2018 01:54:56 AM - INFO - {'nb_neurons': 256, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.4478969230796352, 0.74621212121212122]



01/25/2018 01:55:28 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.75, 'learning_rate': 0.01}
[0.62018378078937531, 0.78787878787878785]



01/25/2018 01:56:00 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.75, 'learning_rate': 0.01}
[0.603506245396354, 0.78409090909090906]



01/25/2018 01:56:45 AM - INFO - {'nb_neurons': 116, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[1.3152652120951451, 0.76136363636363635]



01/25/2018 01:57:32 AM - INFO - {'nb_neurons': 116, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[3.7786119345462685, 0.76136363636363635]



01/25/2018 01:58:06 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[0.90384619005701761, 0.78409090909090906]



01/25/2018 01:59:22 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.75, 'learning_rate': 0.01}
[0.61636438830332319, 0.78409090909090906]



01/25/2018 02:00:06 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.75, 'learning_rate': 0.02}
[5.5703218705726396, 0.65151515151515149]



01/25/2018 02:01:04 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.75, 'learning_rate': 0.02}
[0.68621222087831213, 0.76515151515151514]



01/25/2018 02:01:33 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[0.92141219341393676, 0.77651515151515149]



01/25/2018 02:02:01 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.65, 'learning_rate': 0.01}
[0.76270795952190051, 0.76515151515151514]



01/25/2018 02:02:01 AM - INFO - Generation average: 77.77%
01/25/2018 02:02:01 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 02:02:01 AM - INFO - ***Doing generation 6 of 10***
01/25/2018 02:02:28 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[0.81992272174719605, 0.78787878787878785]



01/25/2018 02:03:00 AM - INFO - {'nb_neurons': 64, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[1.0312277742407538, 0.7992424242424242]



01/25/2018 02:03:31 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[0.74173234087048157, 0.78787878787878785]



01/25/2018 02:04:35 AM - INFO - {'nb_neurons': 122, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.02}
[0.76311071533145325, 0.75378787878787878]



01/25/2018 02:05:18 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[3.5520015340862852, 0.71212121212121215]



01/25/2018 02:06:08 AM - INFO - {'nb_neurons': 88, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.5791730989109386, 0.77272727272727271]



01/25/2018 02:20:51 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adadelta', 'dropout': 0.7, 'learning_rate': 0.02}
[0.54396330768411805, 0.74242424242424243]



01/25/2018 02:21:20 AM - INFO - {'nb_neurons': 64, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.35, 'learning_rate': 0.005}
[1.2114061731280703, 0.76515151515151514]



01/25/2018 02:22:01 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[0.82905656009009387, 0.76136363636363635]



01/25/2018 02:22:57 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.05}
[0.58329743598446704, 0.75378787878787878]



01/25/2018 02:23:31 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.7865387192278197, 0.76136363636363635]



01/25/2018 02:24:07 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.55, 'learning_rate': 0.01}
[0.69867952258297894, 0.78787878787878785]



01/25/2018 02:24:42 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.01}
[1.0448512310783069, 0.77272727272727271]



01/25/2018 02:25:29 AM - INFO - {'nb_neurons': 256, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.05}
[1.0796802820581379, 0.7992424242424242]



01/25/2018 02:26:04 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0194925205274061, 0.79166666666666663]



01/25/2018 02:26:36 AM - INFO - {'nb_neurons': 64, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0260136443557162, 0.79166666666666663]



01/25/2018 02:27:06 AM - INFO - {'nb_neurons': 32, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[0.65829205016295111, 0.76515151515151514]



01/25/2018 02:27:38 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.2035581532752875, 0.79166666666666663]



01/25/2018 02:28:21 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.01}
[0.94518734988841147, 0.77272727272727271]



01/25/2018 02:29:01 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.96485535981077142, 0.78409090909090906]



01/25/2018 02:29:33 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.02}
[0.81309543685479602, 0.77272727272727271]



01/25/2018 02:30:20 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.02}
[0.70150199803439051, 0.77272727272727271]



01/25/2018 02:30:49 AM - INFO - {'nb_neurons': 32, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.1775695916378137, 0.78030303030303028]



01/25/2018 02:31:15 AM - INFO - {'nb_neurons': 32, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.96998599668343866, 0.77651515151515149]



01/25/2018 02:31:52 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.01}
[0.61828116575876868, 0.79545454545454541]



01/25/2018 02:31:52 AM - INFO - Generation average: 78.08%
01/25/2018 02:31:52 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 02:31:52 AM - INFO - ***Doing generation 7 of 10***
01/25/2018 02:32:28 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.3999180522832004, 0.77272727272727271]



01/25/2018 02:33:07 AM - INFO - {'nb_neurons': 108, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.303246183828874, 0.79166666666666663]



01/25/2018 02:33:44 AM - INFO - {'nb_neurons': 72, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[1.4942265365159872, 0.76136363636363635]



01/25/2018 02:34:27 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.0653411104823605, 0.76893939393939392]



01/25/2018 02:35:08 AM - INFO - {'nb_neurons': 122, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.059852462826353, 0.76515151515151514]



01/25/2018 02:35:44 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.01}
[0.94684001171227661, 0.76515151515151514]



01/25/2018 02:36:30 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.01}
[1.491303569891236, 0.76893939393939392]



01/25/2018 02:37:06 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.60294482382861048, 0.78409090909090906]



01/25/2018 02:37:44 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.02}
[0.64762425422668457, 0.75757575757575757]



01/25/2018 02:38:22 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adamax', 'dropout': 0.55, 'learning_rate': 0.01}
[0.73591139731985145, 0.76515151515151514]



01/25/2018 02:39:11 AM - INFO - {'nb_neurons': 122, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.01}
[0.80493294334772858, 0.77651515151515149]



01/25/2018 02:39:45 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.0292843968579264, 0.78030303030303028]



01/25/2018 02:40:18 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[0.72764220020987769, 0.78787878787878785]



01/25/2018 02:40:54 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.05}
[1.1178007649652886, 0.79166666666666663]



01/25/2018 02:41:31 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.70741606481147534, 0.75378787878787878]



01/25/2018 02:42:26 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.05}
[0.64833427378625585, 0.72348484848484851]



01/25/2018 02:43:14 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.6, 'learning_rate': 0.05}
[0.57536158688140637, 0.78787878787878785]



01/25/2018 02:44:05 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.56821699485634314, 0.78787878787878785]



01/25/2018 02:45:44 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[4.1627144669041485, 0.73863636363636365]



01/25/2018 02:46:35 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adamax', 'dropout': 0.7, 'learning_rate': 0.05}
[0.69315193096796668, 0.5]



01/25/2018 02:47:13 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.01}
[1.9542365412820468, 0.77651515151515149]



01/25/2018 02:47:48 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.6005989565993801, 0.74242424242424243]



01/25/2018 02:48:30 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.63838439231569122, 0.80681818181818177]



01/25/2018 02:49:13 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.0499867918816479, 0.78409090909090906]



01/25/2018 02:49:44 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[0.66664805466478516, 0.78030303030303028]



01/25/2018 02:49:44 AM - INFO - Generation average: 77.52%
01/25/2018 02:49:44 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 02:49:44 AM - INFO - ***Doing generation 8 of 10***
01/25/2018 02:50:43 AM - INFO - {'nb_neurons': 256, 'nb_layers': 2, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.89668900677652075, 0.79166666666666663]



01/25/2018 02:51:22 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[1.2668445042588494, 0.73863636363636365]



01/25/2018 02:51:58 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.94034151868386706, 0.78409090909090906]



01/25/2018 02:52:29 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.02}
[1.503878329739426, 0.77272727272727271]



01/25/2018 02:53:05 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.78250183142495877, 0.78030303030303028]



01/25/2018 02:53:55 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.3180432897625547, 0.74242424242424243]



01/25/2018 02:54:44 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.0535528935266263, 0.76893939393939392]



01/25/2018 02:55:27 AM - INFO - {'nb_neurons': 80, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[1.4942480650815098, 0.76515151515151514]



01/25/2018 02:56:25 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.73910988641507702, 0.72727272727272729]



01/25/2018 02:57:15 AM - INFO - {'nb_neurons': 116, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.01}
[0.56661193072795868, 0.78030303030303028]



01/25/2018 02:57:53 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[1.3765452829274265, 0.76893939393939392]



01/25/2018 02:58:53 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.05}
[1.0177480235244289, 0.5]



01/25/2018 02:59:25 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0119325981447191, 0.78787878787878785]



01/25/2018 02:59:58 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.9493539730707804, 0.77651515151515149]



01/25/2018 03:00:37 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.1299546902829951, 0.76893939393939392]



01/25/2018 03:01:13 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.3775749423287131, 0.74621212121212122]



01/25/2018 03:01:49 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.93834778395566076, 0.78030303030303028]



01/25/2018 03:02:33 AM - INFO - {'nb_neurons': 108, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.5181792249733752, 0.77272727272727271]



01/25/2018 03:03:10 AM - INFO - {'nb_neurons': 72, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.2469240730684814, 0.78409090909090906]



01/25/2018 03:03:53 AM - INFO - {'nb_neurons': 108, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.1232492219318042, 0.78030303030303028]



01/25/2018 03:04:35 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[1.1081282984126697, 0.77651515151515149]



01/25/2018 03:05:17 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[0.98535333122267865, 0.7992424242424242]



01/25/2018 03:05:55 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.70459216787959589, 0.78787878787878785]



01/25/2018 03:06:35 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.1715492095911142, 0.79545454545454541]



01/25/2018 03:07:15 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.01}
[0.87803322799278027, 0.75]



01/25/2018 03:07:51 AM - INFO - {'nb_neurons': 64, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[1.2455330775542692, 0.76136363636363635]



01/25/2018 03:09:46 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adam', 'dropout': 0.2, 'learning_rate': 0.05}
[0.71425327026482788, 0.5]



01/25/2018 03:09:46 AM - INFO - Generation average: 76.51%
01/25/2018 03:09:46 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 03:09:46 AM - INFO - ***Doing generation 9 of 10***
01/25/2018 03:10:29 AM - INFO - {'nb_neurons': 108, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.01}
[0.88728780638087879, 0.75757575757575757]



01/25/2018 03:12:15 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.05}
[0.52980826749946131, 0.7007575757575758]



01/25/2018 03:13:03 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.97807202420451422, 0.77651515151515149]



01/25/2018 03:13:54 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.1508880409440307, 0.75378787878787878]



01/25/2018 03:14:45 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.02}
[0.66777006514144666, 0.77651515151515149]



01/25/2018 03:15:22 AM - INFO - {'nb_neurons': 64, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[1.157046100858486, 0.78409090909090906]



01/25/2018 03:16:05 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.96716796448736475, 0.76515151515151514]



01/25/2018 03:25:35 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adadelta', 'dropout': 0.35, 'learning_rate': 0.02}
[0.54426787748481287, 0.75378787878787878]



01/25/2018 03:26:42 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.7, 'learning_rate': 0.02}
[0.5309234478256919, 0.77651515151515149]



01/25/2018 03:27:24 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.01}
[0.55885208872231573, 0.75757575757575757]



01/25/2018 03:28:06 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[0.77290206244497583, 0.76893939393939392]



01/25/2018 03:29:16 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.74769105965440918, 0.77651515151515149]



01/25/2018 03:31:10 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[0.91860468550161878, 0.74621212121212122]



01/25/2018 03:32:21 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[7.9711923599243164, 0.5]



01/25/2018 03:33:02 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.05}
[0.86809920361547754, 0.78409090909090906]



01/25/2018 03:33:55 AM - INFO - {'nb_neurons': 122, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[0.75718956463264697, 0.75757575757575757]



01/25/2018 03:34:33 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.73977949673479249, 0.80681818181818177]



01/25/2018 03:35:13 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0619309366200909, 0.78030303030303028]



01/25/2018 03:35:55 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.89999583115180337, 0.78787878787878785]



01/25/2018 03:36:38 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.01}
[1.6015541007121403, 0.77272727272727271]



01/25/2018 03:37:14 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.01}
[0.77916860941684607, 0.78409090909090906]



01/25/2018 03:48:48 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adadelta', 'dropout': 0.55, 'learning_rate': 0.02}
[0.52412616664713074, 0.75]



01/25/2018 03:49:39 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.01}
[0.58872539640376065, 0.76893939393939392]



01/25/2018 03:50:15 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.02}
[0.62861101555101795, 0.78030303030303028]



01/25/2018 03:50:56 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.83268098984703875, 0.78409090909090906]



01/25/2018 03:51:50 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
[1.0756666019107357, 0.76893939393939392]



01/25/2018 03:52:34 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
[0.73066267913038085, 0.78030303030303028]



01/25/2018 03:53:12 AM - INFO - {'nb_neurons': 64, 'nb_layers': 2, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.02}
[3.9006384863997949, 0.74242424242424243]



01/25/2018 03:53:56 AM - INFO - {'nb_neurons': 64, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.05}
[1.0848327446164507, 0.77651515151515149]



01/25/2018 03:53:56 AM - INFO - Generation average: 77.43%
01/25/2018 03:53:56 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 03:53:56 AM - INFO - ***Doing generation 10 of 10***
01/25/2018 03:54:45 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.96609936981941713, 0.79166666666666663]



01/25/2018 03:55:34 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[1.0433878830888055, 0.78409090909090906]



01/25/2018 03:56:23 AM - INFO - {'nb_neurons': 80, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.01}
[0.7649417686643023, 0.7992424242424242]



01/25/2018 03:57:03 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.55, 'learning_rate': 0.01}
[0.74312897523244226, 0.78787878787878785]



01/25/2018 03:58:07 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.02}
[0.80323540216142486, 0.75757575757575757]



01/25/2018 03:59:06 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.35, 'learning_rate': 0.02}
[5.531897804953835, 0.65530303030303028]



01/25/2018 03:59:48 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.69008324272704846, 0.76893939393939392]



01/25/2018 04:00:31 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'nadam', 'dropout': 0.35, 'learning_rate': 0.02}
[0.78193461804678943, 0.78409090909090906]



01/25/2018 04:01:10 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.35, 'learning_rate': 0.01}
[1.4437232595501523, 0.74621212121212122]



01/25/2018 04:01:53 AM - INFO - {'nb_neurons': 122, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'nadam', 'dropout': 0.35, 'learning_rate': 0.02}
[1.7032833730406833, 0.76515151515151514]



01/25/2018 04:03:04 AM - INFO - {'nb_neurons': 116, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.005}
[1.7226584896896824, 0.75]



01/25/2018 04:04:18 AM - INFO - {'nb_neurons': 116, 'nb_layers': 4, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.02}
[0.69847865899403894, 0.78030303030303028]



01/25/2018 04:05:14 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.02}
[0.92210687617912435, 0.77651515151515149]



01/25/2018 04:05:59 AM - INFO - {'nb_neurons': 108, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'nadam', 'dropout': 0.2, 'learning_rate': 0.02}
[0.77510085385857208, 0.79545454545454541]



01/25/2018 04:06:44 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
[1.0172646966847507, 0.77272727272727271]



01/25/2018 04:07:40 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[1.0763717054417639, 0.79166666666666663]



01/25/2018 04:08:22 AM - INFO - {'nb_neurons': 64, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.55, 'learning_rate': 0.01}
[0.81021547498125024, 0.76515151515151514]



01/25/2018 04:09:01 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'rmsprop', 'dropout': 0.35, 'learning_rate': 0.01}
[1.4545439920867935, 0.77651515151515149]



01/25/2018 04:09:55 AM - INFO - {'nb_neurons': 108, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
[0.9366816634481604, 0.78787878787878785]



01/25/2018 04:10:47 AM - INFO - {'nb_neurons': 128, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.65, 'learning_rate': 0.02}
[0.75451871391498682, 0.78030303030303028]



01/25/2018 04:12:14 AM - INFO - {'nb_neurons': 256, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.05}
[1.211640892606793, 0.77272727272727271]



01/25/2018 04:13:10 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.01}
[1.112733383860552, 0.78030303030303028]



01/25/2018 04:14:29 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.05}
[0.99899285399552551, 0.76515151515151514]



01/25/2018 04:15:56 AM - INFO - {'nb_neurons': 256, 'nb_layers': 4, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.2, 'learning_rate': 0.02}
[0.99117012231638935, 0.78030303030303028]



01/25/2018 04:15:56 AM - INFO - Generation average: 78.11%
01/25/2018 04:15:56 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 04:15:56 AM - INFO - --------------------------------------------------------------------------------
01/25/2018 04:15:56 AM - INFO - {'nb_neurons': 128, 'nb_layers': 4, 'activation': 'elu', 'optimizer': 'adagrad', 'dropout': 0.7, 'learning_rate': 0.05}
01/25/2018 04:15:56 AM - INFO - Network accuracy: 81.06%
01/25/2018 04:15:56 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout': 0.7, 'learning_rate': 0.01}
01/25/2018 04:15:56 AM - INFO - Network accuracy: 80.68%
01/25/2018 04:15:56 AM - INFO - {'nb_neurons': 128, 'nb_layers': 1, 'activation': 'tanh', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.02}
01/25/2018 04:15:56 AM - INFO - Network accuracy: 80.68%
01/25/2018 04:15:56 AM - INFO - {'nb_neurons': 64, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'dropout': 0.35, 'learning_rate': 0.01}
01/25/2018 04:15:56 AM - INFO - Network accuracy: 79.92%
01/25/2018 04:15:56 AM - INFO - {'nb_neurons': 256, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'dropout': 0.2, 'learning_rate': 0.05}
01/25/2018 04:15:56 AM - INFO - Network accuracy: 79.92%









01/25/2018 09:18:20 AM - INFO - ***Evolving 10 generations with population 50***




01/25/2018 09:18:20 AM - INFO - ***Doing generation 1 of 10***
01/25/2018 09:19:06 AM - INFO - {'nb_neurons': 80, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adam', 'funnel': True, 'dropout': 0.45, 'learning_rate': 0.02}
[1.3897501173796076, 0.78030303030303028]



01/25/2018 09:20:54 AM - INFO - {'nb_neurons': 256, 'nb_layers': 5, 'activation': 'tanh', 'optimizer': 'adagrad', 'funnel': True, 'dropout': 0.25, 'learning_rate': 0.05}
[1.0480109597697402, 0.75378787878787878]



01/25/2018 09:21:39 AM - INFO - {'nb_neurons': 108, 'nb_layers': 1, 'activation': 'sigmoid', 'optimizer': 'adamax', 'funnel': True, 'dropout': 0.2, 'learning_rate': 0.05}
[0.75705500714706653, 0.78787878787878785]



01/25/2018 09:22:33 AM - INFO - {'nb_neurons': 108, 'nb_layers': 3, 'activation': 'relu', 'optimizer': 'adagrad', 'funnel': False, 'dropout': 0.4, 'learning_rate': 0.02}
[1.1274804409706232, 0.77651515151515149]



01/25/2018 10:31:54 AM - INFO - {'nb_neurons': 128, 'nb_layers': 2, 'activation': 'sigmoid', 'optimizer': 'adadelta', 'funnel': False, 'dropout': 0.5, 'learning_rate': 0.02}
[0.54181799021634192, 0.74242424242424243]



01/25/2018 10:32:40 AM - INFO - {'nb_neurons': 96, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adamax', 'funnel': False, 'dropout': 0.55, 'learning_rate': 0.02}
[1.0942346607193802, 0.78409090909090906]



01/25/2018 10:46:35 AM - INFO - {'nb_neurons': 108, 'nb_layers': 5, 'activation': 'relu', 'optimizer': 'adadelta', 'funnel': False, 'dropout': 0.4, 'learning_rate': 0.05}
[0.4983974541678573, 0.75]



01/25/2018 10:47:25 AM - INFO - {'nb_neurons': 80, 'nb_layers': 3, 'activation': 'sigmoid', 'optimizer': 'rmsprop', 'funnel': False, 'dropout': 0.9, 'learning_rate': 0.02}
[0.69232121200272534, 0.5]



01/25/2018 10:48:43 AM - INFO - {'nb_neurons': 192, 'nb_layers': 3, 'activation': 'elu', 'optimizer': 'adam', 'funnel': False, 'dropout': 0.5, 'learning_rate': 0.02}
[1.0402314870646505, 0.7007575757575758]



01/25/2018 10:49:41 AM - INFO - {'nb_neurons': 64, 'nb_layers': 5, 'activation': 'sigmoid', 'optimizer': 'adam', 'funnel': False, 'dropout': 0.85, 'learning_rate': 0.02}
[0.69320024866046326, 0.5]



01/25/2018 10:55:39 AM - INFO - {'nb_neurons': 122, 'nb_layers': 5, 'activation': 'elu', 'optimizer': 'adadelta', 'funnel': False, 'dropout': 0.2, 'learning_rate': 0.02}
[0.54370368971969141, 0.72348484848484851]



01/25/2018 11:15:30 AM - INFO - {'nb_neurons': 192, 'nb_layers': 1, 'activation': 'elu', 'optimizer': 'adadelta', 'funnel': True, 'dropout': 0.85, 'learning_rate': 0.01}
[0.59206136970809009, 0.71969696969696972]



01/25/2018 11:17:11 AM - INFO - {'nb_neurons': 256, 'nb_layers': 5, 'activation': 'sigmoid', 'optimizer': 'adagrad', 'funnel': True, 'dropout': 0.25, 'learning_rate': 0.02}
[0.7936316922758565, 0.77651515151515149]



01/25/2018 11:18:04 AM - INFO - {'nb_neurons': 192, 'nb_layers': 1, 'activation': 'relu', 'optimizer': 'adagrad', 'funnel': False, 'dropout': 0.55, 'learning_rate': 0.02}
[0.87962299878850125, 0.80303030303030298]



01/25/2018 11:29:02 AM - INFO - {'nb_neurons': 80, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'adadelta', 'funnel': True, 'dropout': 0.3, 'learning_rate': 0.02}
[0.52380122470133228, 0.75]



